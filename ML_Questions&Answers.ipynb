{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Questions_TeamWork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SudhakarAnemu/AI-DS-ML-DL-Materials/blob/master/ML_Questions%26Answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61VBQ8Ly1XCR",
        "colab_type": "text"
      },
      "source": [
        "## 4th May 2019\n",
        "\n",
        "1. Will it(scaling) taking more time? and what is scaling?<br>\n",
        "Ans : No, \n",
        "ultimately scaling will take the same time. <br>\n",
        "Scaling: is essentially normalization(making sure all values are in the same range). \n",
        "Here are uses of scaling. \n",
        "<br>a. No need to put too much effort into understanding the result. \n",
        "<br>b. No problem even if we do not do it. (Biggest boost can see in the state of processing if we have millions of data instead of 2000 rows). \n",
        "\n",
        "2. How do we optimize the pipeline of the ML for an enterprise?<br>\n",
        "Ans : We need to have Data Science represent Data Set from core data of the enterprise or company. <br>\n",
        "ex: let an organization has 100 different operations from100 different sources. For DS : we need to have a single data source(single representation). in this process, we do scaling. \n",
        "\n",
        "3. Why we will do under root(RMSE) and how does it help you to get the same scale?\n",
        "Ans: It is to normalize the value, basically, it will give the same unit back. <br>\n",
        "ex : Root of 25 is 5\n",
        "\n",
        "4. Describe - ML is nothing but parametric optimization. <br>\n",
        "Ans: for every model, there are \"n\" number of parameters which effects the mathematical logic of calculations, the final learning between X Train and Y Train. <br>\n",
        "Ex : In DJ there is the number of nob's (filter, mixing, up and down etc..) which effects the final results. <br>\n",
        "similarly, this is what experiment will be done in the Data Science perspective \n",
        "\n",
        "5. What is the Grid search? \n",
        "<br>Ans : It will ask you to tell all the combinations that we want to play with(parameters). We will do and run all the those and get back to you with the final result. (it is automation that we wish). Grid search is very heaving in perspective on computations. \n",
        "\n",
        "## 11th May 2019\n",
        "1. What is RMSE, why do we use it?\n",
        "2. Why RMSE is better than R-Square and Adjusted R-Square\n",
        "3. From the example of Sales predict(TV, Newspaper, Radio) : When we remove the NP then the net effect is 30%to40% but when we remove both NP and Radio the net effect is 5%. By this what can we conclude?\n",
        "4. Would not feature selection need trying all combination between features? is there any shortcut in case of a large number of features?\n",
        "5. Why are we removing features? why it is so important?\n",
        "6. Category Data(0,1,2/string's) how we will represent in Linear regression?\n",
        "7. Dummy Variable: what will happen when we take all n variables?\n",
        "8. multiple columns will be created when we apply Dummy on category variables? right, again these individual columns are a category, right? then why are we doing it?\n",
        "9. How can we deal with 100 column's if all are Dummy variables?\n",
        "10. What is the conclusion of a best-fit line?\n",
        "11. From the example of Sales predict(TV, Newspaper, Radio): how confident can we be with the predicted sales value? do we need to give confidence interval based on the RMSE?\n",
        "12. Why Logistic Regression is regression? though it is classification algorithm. \n",
        "13. Let if we have all -ve continuous values as input values, then can we conclude the lower value of RMSE indicates the best fit?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVeo6FzU1XCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}